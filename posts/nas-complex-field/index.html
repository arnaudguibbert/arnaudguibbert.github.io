<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Discovering New Audio Recognition Models with Neural Architecture Search" /><meta name="author" content="Arnaud Guibbert" /><meta property="og:locale" content="en" /><meta name="description" content="A deep dive into automating neural network architecture design for better audio recognition." /><meta property="og:description" content="A deep dive into automating neural network architecture design for better audio recognition." /><link rel="canonical" href="https://arnaudguibbert.github.io/posts/nas-complex-field/" /><meta property="og:url" content="https://arnaudguibbert.github.io/posts/nas-complex-field/" /><meta property="og:site_name" content="Arnaud Guibbert" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-14T12:30:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Discovering New Audio Recognition Models with Neural Architecture Search" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Arnaud Guibbert","url":"https://github.com/arnaudguibbert"},"dateModified":"2022-07-14T12:30:00+02:00","datePublished":"2022-07-14T12:30:00+02:00","description":"A deep dive into automating neural network architecture design for better audio recognition.","headline":"Discovering New Audio Recognition Models with Neural Architecture Search","mainEntityOfPage":{"@type":"WebPage","@id":"https://arnaudguibbert.github.io/posts/nas-complex-field/"},"url":"https://arnaudguibbert.github.io/posts/nas-complex-field/"}</script><title>Discovering New Audio Recognition Models with Neural Architecture Search | Arnaud Guibbert</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Arnaud Guibbert"><meta name="application-name" content="Arnaud Guibbert"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.2/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.27.20/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return 'mode'; } static get MODE_ATTR() { return 'data-mode'; } static get DARK_MODE() { return 'dark'; } static get LIGHT_MODE() { return 'light'; } static get ID() { return 'mode-toggle'; } constructor() { let self = this;this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { self.clearMode(); } self.notify(); }); if (!this.hasMode) { return; } if (this.isDarkMode) { this.setDark(); } else { this.setLight(); } } get sysDarkPrefers() { return window.matchMedia('(prefers-color-scheme: dark)'); } get isPreferDark() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }get modeStatus() { if (this.hasMode) { return this.mode; } else { return this.isPreferDark ? ModeToggle.DARK_MODE : ModeToggle.LIGHT_MODE; } } setDark() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { document.documentElement.removeAttribute(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); }notify() { window.postMessage( { direction: ModeToggle.ID, message: this.modeStatus }, '*' ); } flipMode() { if (this.hasMode) { this.clearMode(); } else { if (this.isPreferDark) { this.setLight(); } else { this.setDark(); } } this.notify(); } } const modeToggle = new ModeToggle(); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/./assets/img/main/profile_picture.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a><h1 class="site-title"> <a href="/">Arnaud Guibbert</a></h1><p class="site-subtitle fst-italic mb-0">Data Scientist - ML engineer</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/about-me/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT ME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>DOCS</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/arnaudguibbert" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="javascript:location.href = 'mailto:' + ['arnaudguibbert','hotmail.fr'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/agcs/?locale=en_US" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>Discovering New Audio Recognition Models with Neural Architecture Search</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1"><header><h1 data-toc-skip>Discovering New Audio Recognition Models with Neural Architecture Search</h1><p class="post-desc fw-light mb-4">A deep dive into automating neural network architecture design for better audio recognition.</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1657794600" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jul 14, 2022 </time> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/arnaudguibbert">Arnaud Guibbert</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1093 words" > <em>6 min</em> read</span></div></div></div></header><div class="content"><blockquote class="prompt-info"><p>This post is a simplified version of our paper on Neural Architecture Search in the complex field for audio recognition. You can read the full paper <a href="/assets/pdf/papers/nas.pdf">here</a>.</p></blockquote><p>Designing a deep neural network can feel like navigating an endless sea of possibilities. With countless options for tweaking hyperparameters, shaping the network’s structure, and deciding on the types of operations to use, the potential configurations are litterally limitless. While some incredibly powerful architectures have been handcrafted—like Transformers, CNNs, GNNs, or U-Net—there’s still a vast uncharted territory of architectures waiting to be discovered.</p><p>This is where <strong>Neural Architecture Search (NAS)</strong> comes into play. NAS aims to automate the process of designing neural network architectures, optimizing not just the weights but the structure itself. Though this can be computationally heavy, NAS has delivered impressive results, especially in fields like image recognition. But let’s clear something up right away: NAS isn’t magic. You still need to define the search space—the range of architectures you want to explore. So, you’re not literally testing <em>every</em> possible configuration.</p><h2 id="two-main-approaches-for-nas"><span class="me-2">Two Main Approaches for NAS</span><a href="#two-main-approaches-for-nas" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>NAS methods generally fall into two categories: those that evaluate each architecture individually and <strong>one-shot</strong> methods that assess multiple architectures simultaneously. One of the most promising one-shot methods is <a href="">DARTS</a>, which uses gradient descent to optimize architectures. Since its introduction, many DARTS variants have been developed, each addressing specific limitations and showing potential for audio applications.</p><p>In our work, we focus on DARTS and its variant, <a href="">FairDARTS</a>, to find the best neural architectures for supervised audio recognition tasks. We also introduce <strong>ForceDARTS</strong>, a new variant inspired by FairDARTS. In addition, we pushed the boundaries of traditional search spaces by incorporating polynomial and complex operations. Finally, while many audio preprocessing methods convert the output of the Short-Time Fourier Transform (STFT) into real numbers, we also explored the benefits of keeping the imaginary components and using complex operations.</p><h2 id="breaking-down-darts-the-basics"><span class="me-2">Breaking Down DARTS: The Basics</span><a href="#breaking-down-darts-the-basics" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>DARTS represents a neural network as a collection of nodes (think of them as points where data is processed) and edges (the operations that connect these points) arranged in a directed acyclic graph (DAG). Each node connects to all previous nodes, and the output of each node is a sum of the operations applied by the connecting edges.</p><p>Formally, each node \(j\) is connected to all preceding nodes \(i\) (where \(i &lt; j\)), and the output of node \(j\) is calculated as:</p><p>\begin{equation} x_j = \sum_{i &lt; j} e_{i,j}(x_i) \end{equation}</p><p>Here, \(e_{i,j}(x_i)\) represents the output of the edge connecting node \(i\) to node \(j\). For each edge, there is a set of \(M\) candidate operations, \(O = \{o^1, o^2, ..., o^M\}\), which defines the search space. All edges share the same set of operations. The challenge is to determine the best operation for each edge. Ideally, you’d have a one-hot vector \(\beta_{i,j}^{o} \in \{0,1\}\) that selects one operation among the \(M\) possible ones.</p><p>In DARTS, this problem is relaxed by introducing a coefficient \(\alpha_{i,j}^o \in \mathbb{R}\) associated with each operation \(o \in O\). The vector \(\alpha_{i,j}\) contains all the \(\alpha_{i,j}^o\) values, and the one-hot vector \(\beta_{i,j}\) is approximated by applying the softmax function to \(\alpha_{i,j}\). Given an input \(x\), the output of an edge \(e_{i,j}\) is computed as:</p><p>\begin{equation} e_{i,j}(x) = \sum_{o \in O} \frac{\exp(\alpha_{i,j}^o)}{\sum_{o’ \in O} \exp(\alpha_{i,j}^{o’})} o(x) \approx \sum_{o \in O} \beta_{i,j}^{o} o(x) \end{equation}</p><p>The architecture is fully defined by the concatenation of all the \(\alpha_{i,j}\) vectors for \(i &lt; j\). Let’s denote this vector by \(\alpha\). Finding the best architecture comes down to finding the optimal \(\alpha\), denoted as \(\alpha^*\). The goal is to minimize the validation loss over \(\alpha\) while simultaneously finding the best weights \(w^*(\alpha)\) for this architecture during training. This is a bi-level optimization problem.</p><p>Once the best architecture \(\alpha^*\) is found, the operation with the highest coefficient is selected for each edge:</p><p>\begin{equation} o_{i,j} = \arg\max_{o \in O} \alpha_{i,j}^o \end{equation}</p><p>This step is known as the <strong>pruning operation</strong>.</p><h3 id="visualizing-darts"><span class="me-2">Visualizing DARTS</span><a href="#visualizing-darts" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Here is a video that provides good visual explanation of the core concepts DARTS with nice visualizations.</p><iframe class="embed-video" loading="lazy" src="https://www.youtube.com/embed/imUcDpohtis" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h2 id="forcedarts-reducing-the-impact-of-pruning"><span class="me-2">ForceDARTS: reducing the impact of pruning</span><a href="#forcedarts-reducing-the-impact-of-pruning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>DARTS has its drawbacks, particularly during the pruning process. The gap between the one-shot model and the pruned model can be significant, which can negatively impact performance. ForceDARTS aims to reduce this gap by gently pushing the algorithm to select architectures that are closer to a one-hot structure for architectural weights and multi-hot for edge weights.</p><p>While <a href="">FairDARTS</a> addresses this by pushing the architectural weights towards 0 or 1, it doesn’t explicitly force them into a one-hot structure. ForceDARTS takes this a step further by reintroducing the original softmax function and adding a loss that encourages the architecture to lean towards a pure distribution—a one-hot vector. This loss is inspired by purity measures used in decision trees, like <strong>Gini impurity</strong> and <strong>Entropy</strong>.</p><p>Given a distribution \(p = \{p_1,p_2, ..., p_C\}\), these purity measures are defined as:</p><p>\begin{equation} Gini(p) = \sum_{i = 1}^C p_i(1 - p_i) \quad E(p) = - \sum_{i = 1}^C p_i \log(p_i) \quad \text{s.t.} \quad \sum_{i = 1}^C p_i = 1 \label{eq:purity_function} \end{equation}</p><p>Both reach their minimum value (0) for a pure distribution and their maximum value (\((C-1)/C\) for Gini impurity and \(\log(C)\) for Entropy) for an impure distribution. The differences in architectural weights obtained with DARTS, FairDARTS, and ForceDARTS are shown in the figure below:</p><p><a href="/../assets/img/posts/nas/alpha_evolution.png" class="popup img-link shimmer"><img src="/../assets/img/posts/nas/alpha_evolution.png" alt="" loading="lazy"></a> <em>Figure 1: Final architectural weights \(\alpha\) obtained with DARTS (left), FairDARTS (middle), and ForceDARTS (right)</em></p><h2 id="diversifying-the-search-space"><span class="me-2">Diversifying the Search Space</span><a href="#diversifying-the-search-space" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Beyond the method itself, existing NAS methods can be improved by optimizing the search space. Most studies using DARTS stick to the original search space defined in the DARTS paper. In our work, we diversified the search space by introducing polynomial operations. Our goal was to see how these new operations could improve the final results. Below is a figure showing some of the polynomial operations we introduced:</p><p><a href="/../assets/img/posts/nas/search_space_polynomial.png" class="popup img-link shimmer"><img src="/../assets/img/posts/nas/search_space_polynomial.png" alt="" loading="lazy"></a> <em>Figure 2: Polynomial operations introduced into the search space, for more information check the paper</em></p><h2 id="what-we-found"><span class="me-2">What We Found</span><a href="#what-we-found" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We tested our methods on an audio dataset using both real and complex neural networks. The details are in the <a href="/assets/pdf/papers/nas.pdf">paper</a>, but here’s the gist:</p><p>Our main goal was to explore new and existing methods in NAS for audio recognition in the complex field. We proposed ForceDARTS, a DARTS variant that showed better performance than DARTS and was on par with FairDARTS. Additionally, we diversified the search space by introducing pairwise operations. This diversification yielded results similar to those with the original search space, though it also increased the risk of ending up with an unstable architecture, especially when polynomial operations were heavily used.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/projects/">Projects</a>, <a href="/categories/research/">Research</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/research/" class="post-tag no-text-decoration" >Research</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep Learning</a> <a href="/tags/nas/" class="post-tag no-text-decoration" >NAS</a> <a href="/tags/speech-recognition/" class="post-tag no-text-decoration" >Speech Recognition</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Discovering%20New%20Audio%20Recognition%20Models%20with%20Neural%20Architecture%20Search%20-%20Arnaud%20Guibbert&url=https%3A%2F%2Farnaudguibbert.github.io%2Fposts%2Fnas-complex-field%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Discovering%20New%20Audio%20Recognition%20Models%20with%20Neural%20Architecture%20Search%20-%20Arnaud%20Guibbert&u=https%3A%2F%2Farnaudguibbert.github.io%2Fposts%2Fnas-complex-field%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Farnaudguibbert.github.io%2Fposts%2Fnas-complex-field%2F&text=Discovering%20New%20Audio%20Recognition%20Models%20with%20Neural%20Architecture%20Search%20-%20Arnaud%20Guibbert" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Farnaudguibbert.github.io%2Fposts%2Fnas-complex-field%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Linkedin" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/knowledge-graph-abs/">Knowledge graph abstraction layers</a><li class="text-truncate lh-lg"> <a href="/posts/nas-complex-field/">Discovering New Audio Recognition Models with Neural Architecture Search</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/ml/">ML</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">Research</a> <a class="post-tag btn btn-outline-primary" href="/tags/graph-theory/">Graph Theory</a> <a class="post-tag btn btn-outline-primary" href="/tags/nas/">NAS</a> <a class="post-tag btn btn-outline-primary" href="/tags/speech-recognition/">Speech Recognition</a></div></section></div><section id="toc-wrapper" class="d-none ps-0 pe-4"><h2 class="panel-heading ps-3 mb-2">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/knowledge-graph-abs/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1680345000" data-df="ll" > Apr 1, 2023 </time><h4 class="pt-0 my-2">Knowledge graph abstraction layers</h4><div class="text-muted"><p>Knowledge Graphs (KGs) have become a go-to method for storing and organizing complex real-world data. Unfortunately their size make them difficult to manage and understand. Let&#39;s see how we can tra...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"><div class="btn btn-outline-primary disabled" aria-label="Older"><p>-</p></div><a href="/posts/knowledge-graph-abs/" class="btn btn-outline-primary" aria-label="Newer" ><p>Knowledge graph abstraction layers</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://github.com/arnaudguibbert">arnaud guibbert</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.0.1" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/ml/">ML</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">Research</a> <a class="post-tag btn btn-outline-primary" href="/tags/graph-theory/">Graph Theory</a> <a class="post-tag btn btn-outline-primary" href="/tags/nas/">NAS</a> <a class="post-tag btn btn-outline-primary" href="/tags/speech-recognition/">Speech Recognition</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.11/dayjs.min.js,npm/dayjs@1.11.11/locale/en.min.js,npm/dayjs@1.11.11/plugin/relativeTime.min.js,npm/dayjs@1.11.11/plugin/localizedFormat.min.js,npm/tocbot@4.27.20/dist/tocbot.min.js"></script> <script src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js"></script> <script>SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
